{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": "import requests, zipfile, io\nfrom datasets import load_dataset"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": "from torch.utils.data import Dataset\nimport os\nfrom PIL import Image\n\nclass SemanticSegmentationDataset(Dataset):\n    \"\"\"Image (semantic) segmentation dataset.\"\"\"\n\n    def __init__(self, root_dir, feature_extractor, train=True):\n        \"\"\"\n        Args:\n            root_dir (string): Root directory of the dataset containing the images + annotations.\n            feature_extractor (SegFormerFeatureExtractor): feature extractor to prepare images + segmentation maps.\n            train (bool): Whether to load \"training\" or \"validation\" images + annotations.\n        \"\"\"\n        self.root_dir = root_dir\n        self.feature_extractor = feature_extractor\n        self.train = train\n\n        sub_path = \"train\" if self.train else \"validation\"\n        self.img_dir = os.path.join(self.root_dir, sub_path, \"rgb\")\n        self.ann_dir = os.path.join(self.root_dir, sub_path, \"labels\")\n        \n        # read images\n        image_file_names = []\n        for root, dirs, files in os.walk(self.img_dir):\n          image_file_names.extend(files)\n        self.images = sorted(image_file_names)\n        \n        # read annotations\n        annotation_file_names = []\n        for root, dirs, files in os.walk(self.ann_dir):\n          annotation_file_names.extend(files)\n        self.annotations = sorted(annotation_file_names)\n\n        assert len(self.images) == len(self.annotations), \"There must be as many images as there are segmentation maps\"\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        \n        image = Image.open(os.path.join(self.img_dir, self.images[idx]))\n        segmentation_map = Image.open(os.path.join(self.ann_dir, self.annotations[idx]))\n\n        # randomly crop + pad both image and segmentation map to same size\n        encoded_inputs = self.feature_extractor(image, segmentation_map, return_tensors=\"pt\")\n\n        for k,v in encoded_inputs.items():\n          encoded_inputs[k].squeeze_() # remove batch dimension\n\n        return encoded_inputs"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/home/klimenko/anaconda3/envs/facade/lib/python3.10/site-packages/transformers/models/segformer/feature_extraction_segformer.py:28: FutureWarning: The class SegformerFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use SegformerImageProcessor instead.\n  warnings.warn(\n/home/klimenko/anaconda3/envs/facade/lib/python3.10/site-packages/transformers/models/segformer/image_processing_segformer.py:99: FutureWarning: The `reduce_labels` parameter is deprecated and will be removed in a future version. Please use `do_reduce_labels` instead.\n  warnings.warn(\n"
    }
   ],
   "source": "from transformers import SegformerFeatureExtractor\n\nroot_dir = '/home/klimenko/seg_materials/VAL_SEGFORMER/data/4/'# '/home/klimenko/facade_materials/materials/'\nfeature_extractor = SegformerFeatureExtractor(reduce_labels=True)\n\ntrain_dataset = SemanticSegmentationDataset(root_dir=root_dir, feature_extractor=feature_extractor)\nvalid_dataset = SemanticSegmentationDataset(root_dir=root_dir, feature_extractor=feature_extractor, train=False)"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Number of training examples: 121\nNumber of validation examples: 23\n"
    }
   ],
   "source": "print(\"Number of training examples:\", len(train_dataset))\nprint(\"Number of validation examples:\", len(valid_dataset))"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": "from torch.utils.data import DataLoader\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)\nvalid_dataloader = DataLoader(valid_dataset, batch_size=1)"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/home/klimenko/anaconda3/envs/facade/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n/home/klimenko/anaconda3/envs/facade/lib/python3.10/site-packages/transformers/modeling_utils.py:442: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  return torch.load(checkpoint_file, map_location=\"cpu\")\nSome weights of the model checkpoint at nvidia/mit-b0 were not used when initializing SegformerForSemanticSegmentation: ['classifier.weight', 'classifier.bias']\n- This IS expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head.linear_c.3.proj.weight', 'decode_head.linear_c.0.proj.weight', 'decode_head.classifier.weight', 'decode_head.linear_c.2.proj.bias', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.batch_norm.weight', 'decode_head.linear_c.0.proj.bias', 'decode_head.classifier.bias', 'decode_head.batch_norm.bias', 'decode_head.linear_c.3.proj.bias', 'decode_head.linear_fuse.weight', 'decode_head.batch_norm.running_mean', 'decode_head.linear_c.2.proj.weight', 'decode_head.batch_norm.running_var', 'decode_head.linear_c.1.proj.weight', 'decode_head.linear_c.1.proj.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
    }
   ],
   "source": "from transformers import SegformerForSemanticSegmentation\nimport json\nfrom huggingface_hub import cached_download, hf_hub_url, hf_hub_download\n\n# load id2label mapping from a JSON on the hub\nid2label = json.load(open('materials.json'))\nid2label = {int(k): v for k, v in id2label.items()}\nlabel2id = {v: k for k, v in id2label.items()}\n\n# define model\nmodel = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/mit-b0\",\n                                                         num_labels=7, \n                                                         id2label=id2label, \n                                                         label2id=label2id,\n)\n"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": "from datasets import load_metric\nmetric = load_metric(\"mean_iou\")"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch: 0\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613b6576310d47b4ace59e506cacf215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/13 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7843279356554bc3bbe94d8a0e3b35dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/home/klimenko/.cache/huggingface/modules/datasets_modules/metrics/mean_iou/927b58f57da3f4b6e385e47d8a4b3947ee3f7cfcdba9b9359eba2ada2ed6b951/mean_iou.py:259: RuntimeWarning: invalid value encountered in divide\n  acc = total_area_intersect / total_area_label\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "idx:  0  Loss: 1.88071  Mean_iou: 0.062  Mean accuracy: 0.223\nidx:  1  Loss: 1.69356  Mean_iou: 0.364  Mean accuracy: 0.471\nidx:  2  Loss: 1.76160  Mean_iou: 0.221  Mean accuracy: 0.372\nidx:  3  Loss: 1.92636  Mean_iou: 0.022  Mean accuracy: 0.113\nidx:  4  Loss: 1.81595  Mean_iou: 0.105  Mean accuracy: 0.185\nidx:  5  Loss: 1.83824  Mean_iou: 0.056  Mean accuracy: 0.175\n"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/home/klimenko/.cache/huggingface/modules/datasets_modules/metrics/mean_iou/927b58f57da3f4b6e385e47d8a4b3947ee3f7cfcdba9b9359eba2ada2ed6b951/mean_iou.py:258: RuntimeWarning: invalid value encountered in divide\n  iou = total_area_intersect / total_area_union\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "idx:  6  Loss: 1.72436  Mean_iou: 0.179  Mean accuracy: 0.284\nidx:  7  Loss: 1.75097  Mean_iou: 0.189  Mean accuracy: 0.318\nidx:  8  Loss: 1.67079  Mean_iou: 0.170  Mean accuracy: 0.418\nidx:  9  Loss: 1.79329  Mean_iou: 0.105  Mean accuracy: 0.226\nidx:  10  Loss: 1.90454  Mean_iou: 0.028  Mean accuracy: 0.191\nidx:  11  Loss: 1.82430  Mean_iou: 0.084  Mean accuracy: 0.196\nidx:  12  Loss: 1.63593  Mean_iou: 0.222  Mean accuracy: 0.325\nidx:  13  Loss: 1.72226  Mean_iou: 0.198  Mean accuracy: 0.273\nidx:  14  Loss: 1.75188  Mean_iou: 0.088  Mean accuracy: 0.170\nidx:  15  Loss: 1.72929  Mean_iou: 0.198  Mean accuracy: 0.301\nidx:  16  Loss: 1.73056  Mean_iou: 0.206  Mean accuracy: 0.295\nidx:  17  Loss: 1.82725  Mean_iou: 0.143  Mean accuracy: 0.284\nidx:  18  Loss: 1.50481  Mean_iou: 0.230  Mean accuracy: 0.348\nidx:  19  Loss: 1.62975  Mean_iou: 0.259  Mean accuracy: 0.378\nidx:  20  Loss: 1.87397  Mean_iou: 0.041  Mean accuracy: 0.175\nidx:  21  Loss: 1.73183  Mean_iou: 0.179  Mean accuracy: 0.300\nidx:  22  Loss: 1.81738  Mean_iou: 0.096  Mean accuracy: 0.342\nloss mean  1.7625944458920022\nEpoch: 1\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e518c322f5340ddabe9a6038290377d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/13 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5c828e15ce422e803441098e78b24e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "idx:  0  Loss: 1.63332  Mean_iou: 0.065  Mean accuracy: 0.160\nidx:  1  Loss: 1.18432  Mean_iou: 0.432  Mean accuracy: 0.466\nidx:  2  Loss: 1.18535  Mean_iou: 0.287  Mean accuracy: 0.364\nidx:  3  Loss: 1.83413  Mean_iou: 0.053  Mean accuracy: 0.173\nidx:  4  Loss: 1.51373  Mean_iou: 0.129  Mean accuracy: 0.206\nidx:  5  Loss: 1.59234  Mean_iou: 0.057  Mean accuracy: 0.178\nidx:  6  Loss: 1.24090  Mean_iou: 0.291  Mean accuracy: 0.407\nidx:  7  Loss: 1.23742  Mean_iou: 0.239  Mean accuracy: 0.333\nidx:  8  Loss: 1.21257  Mean_iou: 0.229  Mean accuracy: 0.409\nidx:  9  Loss: 1.48915  Mean_iou: 0.125  Mean accuracy: 0.205\nidx:  10  Loss: 1.80579  Mean_iou: 0.028  Mean accuracy: 0.195\nidx:  11  Loss: 1.57979  Mean_iou: 0.094  Mean accuracy: 0.208\nidx:  12  Loss: 0.99734  Mean_iou: 0.247  Mean accuracy: 0.348\nidx:  13  Loss: 1.25423  Mean_iou: 0.286  Mean accuracy: 0.309\nidx:  14  Loss: 1.34238  Mean_iou: 0.111  Mean accuracy: 0.174\nidx:  15  Loss: 1.36347  Mean_iou: 0.194  Mean accuracy: 0.299\nidx:  16  Loss: 1.32234  Mean_iou: 0.215  Mean accuracy: 0.297\nidx:  17  Loss: 1.51002  Mean_iou: 0.223  Mean accuracy: 0.343\nidx:  18  Loss: 0.83635  Mean_iou: 0.306  Mean accuracy: 0.337\nidx:  19  Loss: 0.92465  Mean_iou: 0.358  Mean accuracy: 0.375\nidx:  20  Loss: 1.73593  Mean_iou: 0.044  Mean accuracy: 0.182\nidx:  21  Loss: 1.31547  Mean_iou: 0.209  Mean accuracy: 0.305\nidx:  22  Loss: 1.51945  Mean_iou: 0.256  Mean accuracy: 0.386\nloss mean  1.3752423291621\nEpoch: 2\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae02b552aaa4fa18e6d23ae62d5a018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/13 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0199de500643069e4f3c80994e5530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "idx:  0  Loss: 1.50346  Mean_iou: 0.066  Mean accuracy: 0.165\nidx:  1  Loss: 0.91569  Mean_iou: 0.367  Mean accuracy: 0.484\nidx:  2  Loss: 0.79797  Mean_iou: 0.288  Mean accuracy: 0.350\nidx:  3  Loss: 1.72221  Mean_iou: 0.063  Mean accuracy: 0.197\nidx:  4  Loss: 1.28318  Mean_iou: 0.133  Mean accuracy: 0.214\nidx:  5  Loss: 1.47254  Mean_iou: 0.076  Mean accuracy: 0.182\nidx:  6  Loss: 1.12622  Mean_iou: 0.290  Mean accuracy: 0.413\nidx:  7  Loss: 0.84703  Mean_iou: 0.252  Mean accuracy: 0.330\nidx:  8  Loss: 1.05894  Mean_iou: 0.202  Mean accuracy: 0.425\nidx:  9  Loss: 1.50060  Mean_iou: 0.127  Mean accuracy: 0.228\nidx:  10  Loss: 1.68641  Mean_iou: 0.035  Mean accuracy: 0.203\nidx:  11  Loss: 1.40996  Mean_iou: 0.101  Mean accuracy: 0.210\nidx:  12  Loss: 0.76526  Mean_iou: 0.229  Mean accuracy: 0.324\nidx:  13  Loss: 0.98063  Mean_iou: 0.294  Mean accuracy: 0.323\nidx:  14  Loss: 1.20064  Mean_iou: 0.112  Mean accuracy: 0.176\nidx:  15  Loss: 1.23475  Mean_iou: 0.193  Mean accuracy: 0.301\nidx:  16  Loss: 1.33250  Mean_iou: 0.164  Mean accuracy: 0.314\nidx:  17  Loss: 1.32757  Mean_iou: 0.230  Mean accuracy: 0.331\nidx:  18  Loss: 0.66435  Mean_iou: 0.300  Mean accuracy: 0.333\nidx:  19  Loss: 0.59344  Mean_iou: 0.358  Mean accuracy: 0.379\nidx:  20  Loss: 1.64547  Mean_iou: 0.058  Mean accuracy: 0.202\nidx:  21  Loss: 1.23825  Mean_iou: 0.201  Mean accuracy: 0.304\nidx:  22  Loss: 1.31859  Mean_iou: 0.237  Mean accuracy: 0.411\nloss mean  1.2011206512865813\nEpoch: 3\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f208a8ddf847cc9ae4a63c7a98533b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/13 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d443fcfe69d4335a6c32b617e524cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "idx:  0  Loss: 1.40290  Mean_iou: 0.078  Mean accuracy: 0.162\nidx:  1  Loss: 0.76001  Mean_iou: 0.424  Mean accuracy: 0.492\nidx:  2  Loss: 0.72790  Mean_iou: 0.330  Mean accuracy: 0.383\nidx:  3  Loss: 1.42593  Mean_iou: 0.200  Mean accuracy: 0.294\nidx:  4  Loss: 1.16194  Mean_iou: 0.180  Mean accuracy: 0.283\nidx:  5  Loss: 1.46400  Mean_iou: 0.083  Mean accuracy: 0.186\nidx:  6  Loss: 0.80232  Mean_iou: 0.337  Mean accuracy: 0.415\nidx:  7  Loss: 0.67438  Mean_iou: 0.268  Mean accuracy: 0.340\nidx:  8  Loss: 0.99290  Mean_iou: 0.291  Mean accuracy: 0.412\nidx:  9  Loss: 1.20648  Mean_iou: 0.140  Mean accuracy: 0.207\nidx:  10  Loss: 1.68138  Mean_iou: 0.042  Mean accuracy: 0.214\nidx:  11  Loss: 1.38366  Mean_iou: 0.099  Mean accuracy: 0.211\nidx:  12  Loss: 0.65351  Mean_iou: 0.252  Mean accuracy: 0.315\nidx:  13  Loss: 0.82482  Mean_iou: 0.288  Mean accuracy: 0.312\nidx:  14  Loss: 1.20526  Mean_iou: 0.103  Mean accuracy: 0.169\nidx:  15  Loss: 1.22716  Mean_iou: 0.206  Mean accuracy: 0.299\nidx:  16  Loss: 0.94509  Mean_iou: 0.228  Mean accuracy: 0.310\nidx:  17  Loss: 1.19195  Mean_iou: 0.246  Mean accuracy: 0.348\nidx:  18  Loss: 0.59005  Mean_iou: 0.264  Mean accuracy: 0.303\nidx:  19  Loss: 0.43340  Mean_iou: 0.342  Mean accuracy: 0.363\nidx:  20  Loss: 1.40577  Mean_iou: 0.115  Mean accuracy: 0.233\nidx:  21  Loss: 1.30963  Mean_iou: 0.216  Mean accuracy: 0.304\nidx:  22  Loss: 1.00768  Mean_iou: 0.393  Mean accuracy: 0.448\nloss mean  1.0642711818218231\nEpoch: 4\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21b33ef559034edf8e3017605f30c686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/13 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965c59fabb7e4e4d96dcd32acbfb8918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "idx:  0  Loss: 1.14096  Mean_iou: 0.130  Mean accuracy: 0.201\nidx:  1  Loss: 0.84205  Mean_iou: 0.398  Mean accuracy: 0.475\nidx:  2  Loss: 0.65945  Mean_iou: 0.304  Mean accuracy: 0.335\nidx:  3  Loss: 1.16254  Mean_iou: 0.254  Mean accuracy: 0.290\nidx:  4  Loss: 1.06846  Mean_iou: 0.172  Mean accuracy: 0.272\nidx:  5  Loss: 1.33991  Mean_iou: 0.105  Mean accuracy: 0.205\nidx:  6  Loss: 0.81577  Mean_iou: 0.342  Mean accuracy: 0.431\nidx:  7  Loss: 0.55385  Mean_iou: 0.293  Mean accuracy: 0.341\nidx:  8  Loss: 0.91573  Mean_iou: 0.252  Mean accuracy: 0.435\nidx:  9  Loss: 1.29113  Mean_iou: 0.137  Mean accuracy: 0.219\nidx:  10  Loss: 1.56358  Mean_iou: 0.062  Mean accuracy: 0.244\nidx:  11  Loss: 1.30811  Mean_iou: 0.099  Mean accuracy: 0.201\nidx:  12  Loss: 0.61084  Mean_iou: 0.264  Mean accuracy: 0.324\nidx:  13  Loss: 0.86611  Mean_iou: 0.218  Mean accuracy: 0.304\nidx:  14  Loss: 1.20781  Mean_iou: 0.102  Mean accuracy: 0.168\nidx:  15  Loss: 1.15037  Mean_iou: 0.206  Mean accuracy: 0.302\nidx:  16  Loss: 1.01363  Mean_iou: 0.219  Mean accuracy: 0.325\nidx:  17  Loss: 1.20049  Mean_iou: 0.267  Mean accuracy: 0.328\nidx:  18  Loss: 0.52662  Mean_iou: 0.290  Mean accuracy: 0.325\nidx:  19  Loss: 0.36996  Mean_iou: 0.355  Mean accuracy: 0.373\nidx:  20  Loss: 1.31499  Mean_iou: 0.149  Mean accuracy: 0.252\nidx:  21  Loss: 1.34600  Mean_iou: 0.212  Mean accuracy: 0.305\nidx:  22  Loss: 0.87271  Mean_iou: 0.398  Mean accuracy: 0.449\nloss mean  1.0061391423577848\nEpoch: 5\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3f99b1aa5940799c3ca9f4ac1f4ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/13 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e18b4df8424dbfb0274a571eef51c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "idx:  0  Loss: 1.18139  Mean_iou: 0.099  Mean accuracy: 0.177\nidx:  1  Loss: 0.62814  Mean_iou: 0.410  Mean accuracy: 0.450\nidx:  2  Loss: 0.62548  Mean_iou: 0.281  Mean accuracy: 0.335\nidx:  3  Loss: 0.98928  Mean_iou: 0.244  Mean accuracy: 0.287\nidx:  4  Loss: 1.17607  Mean_iou: 0.124  Mean accuracy: 0.205\nidx:  5  Loss: 1.11753  Mean_iou: 0.185  Mean accuracy: 0.258\nidx:  6  Loss: 0.82190  Mean_iou: 0.331  Mean accuracy: 0.448\nidx:  7  Loss: 0.45623  Mean_iou: 0.292  Mean accuracy: 0.332\nidx:  8  Loss: 0.85144  Mean_iou: 0.327  Mean accuracy: 0.444\nidx:  9  Loss: 1.30304  Mean_iou: 0.136  Mean accuracy: 0.224\nidx:  10  Loss: 1.39055  Mean_iou: 0.108  Mean accuracy: 0.299\nidx:  11  Loss: 1.25079  Mean_iou: 0.120  Mean accuracy: 0.206\nidx:  12  Loss: 0.56831  Mean_iou: 0.298  Mean accuracy: 0.348\nidx:  13  Loss: 0.70398  Mean_iou: 0.230  Mean accuracy: 0.270\nidx:  14  Loss: 1.12313  Mean_iou: 0.108  Mean accuracy: 0.170\nidx:  15  Loss: 1.10709  Mean_iou: 0.210  Mean accuracy: 0.305\nidx:  16  Loss: 1.05270  Mean_iou: 0.225  Mean accuracy: 0.356\nidx:  17  Loss: 1.31267  Mean_iou: 0.186  Mean accuracy: 0.267\nidx:  18  Loss: 0.57535  Mean_iou: 0.245  Mean accuracy: 0.324\nidx:  19  Loss: 0.48887  Mean_iou: 0.351  Mean accuracy: 0.385\nidx:  20  Loss: 1.24270  Mean_iou: 0.161  Mean accuracy: 0.247\nidx:  21  Loss: 1.31060  Mean_iou: 0.211  Mean accuracy: 0.305\nidx:  22  Loss: 0.79332  Mean_iou: 0.312  Mean accuracy: 0.435\nloss mean  0.9595943352450496\nEpoch: 6\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a5964ce4a414ceca9a4cc041c0dc168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/13 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e328587988404f0193ef92672e42a48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "idx:  0  Loss: 1.20328  Mean_iou: 0.126  Mean accuracy: 0.223\nidx:  1  Loss: 0.69467  Mean_iou: 0.361  Mean accuracy: 0.440\nidx:  2  Loss: 0.74884  Mean_iou: 0.286  Mean accuracy: 0.353\nidx:  3  Loss: 0.85941  Mean_iou: 0.264  Mean accuracy: 0.309\nidx:  4  Loss: 1.03948  Mean_iou: 0.172  Mean accuracy: 0.272\nidx:  5  Loss: 1.15209  Mean_iou: 0.164  Mean accuracy: 0.251\nidx:  6  Loss: 0.80353  Mean_iou: 0.352  Mean accuracy: 0.442\nidx:  7  Loss: 0.46748  Mean_iou: 0.299  Mean accuracy: 0.342\nidx:  8  Loss: 0.85084  Mean_iou: 0.332  Mean accuracy: 0.448\nidx:  9  Loss: 1.26012  Mean_iou: 0.137  Mean accuracy: 0.215\nidx:  10  Loss: 1.65822  Mean_iou: 0.064  Mean accuracy: 0.251\nidx:  11  Loss: 1.30668  Mean_iou: 0.109  Mean accuracy: 0.221\nidx:  12  Loss: 0.59558  Mean_iou: 0.263  Mean accuracy: 0.322\nidx:  13  Loss: 0.71419  Mean_iou: 0.244  Mean accuracy: 0.323\nidx:  14  Loss: 1.10146  Mean_iou: 0.107  Mean accuracy: 0.176\nidx:  15  Loss: 1.03146  Mean_iou: 0.213  Mean accuracy: 0.304\nidx:  16  Loss: 0.93844  Mean_iou: 0.198  Mean accuracy: 0.312\nidx:  17  Loss: 1.40050  Mean_iou: 0.125  Mean accuracy: 0.244\nidx:  18  Loss: 0.51710  Mean_iou: 0.226  Mean accuracy: 0.342\nidx:  19  Loss: 0.38258  Mean_iou: 0.363  Mean accuracy: 0.381\nidx:  20  Loss: 1.07243  Mean_iou: 0.175  Mean accuracy: 0.254\nidx:  21  Loss: 1.31758  Mean_iou: 0.208  Mean accuracy: 0.302\nidx:  22  Loss: 0.60522  Mean_iou: 0.309  Mean accuracy: 0.434\nloss mean  0.944405339334322\nEpoch: 7\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f560a8f5034b436688b639968a1e196f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/13 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c199502927f94575b4af6ed5b416d17c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "idx:  0  Loss: 0.95171  Mean_iou: 0.203  Mean accuracy: 0.266\nidx:  1  Loss: 0.65160  Mean_iou: 0.395  Mean accuracy: 0.454\nidx:  2  Loss: 0.77571  Mean_iou: 0.351  Mean accuracy: 0.410\nidx:  3  Loss: 0.48536  Mean_iou: 0.269  Mean accuracy: 0.304\nidx:  4  Loss: 0.96448  Mean_iou: 0.192  Mean accuracy: 0.303\nidx:  5  Loss: 0.92717  Mean_iou: 0.195  Mean accuracy: 0.262\nidx:  6  Loss: 0.62898  Mean_iou: 0.370  Mean accuracy: 0.448\nidx:  7  Loss: 0.43431  Mean_iou: 0.317  Mean accuracy: 0.358\nidx:  8  Loss: 0.84059  Mean_iou: 0.328  Mean accuracy: 0.444\nidx:  9  Loss: 1.19567  Mean_iou: 0.143  Mean accuracy: 0.220\nidx:  10  Loss: 1.48753  Mean_iou: 0.092  Mean accuracy: 0.261\nidx:  11  Loss: 1.02938  Mean_iou: 0.180  Mean accuracy: 0.239\nidx:  12  Loss: 0.57463  Mean_iou: 0.270  Mean accuracy: 0.328\nidx:  13  Loss: 0.71370  Mean_iou: 0.217  Mean accuracy: 0.283\nidx:  14  Loss: 1.11029  Mean_iou: 0.107  Mean accuracy: 0.170\nidx:  15  Loss: 0.95488  Mean_iou: 0.251  Mean accuracy: 0.328\nidx:  16  Loss: 0.77256  Mean_iou: 0.244  Mean accuracy: 0.309\nidx:  17  Loss: 1.31833  Mean_iou: 0.147  Mean accuracy: 0.263\nidx:  18  Loss: 0.44118  Mean_iou: 0.306  Mean accuracy: 0.337\nidx:  19  Loss: 0.32202  Mean_iou: 0.358  Mean accuracy: 0.375\nidx:  20  Loss: 0.87720  Mean_iou: 0.195  Mean accuracy: 0.258\nidx:  21  Loss: 1.40424  Mean_iou: 0.213  Mean accuracy: 0.307\nidx:  22  Loss: 0.49040  Mean_iou: 0.377  Mean accuracy: 0.417\nloss mean  0.8413932349370874\nEpoch: 8\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d3071869c04480bfe8d182547313f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/13 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adcec876cbc143318828b075154ecff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "idx:  0  Loss: 1.27677  Mean_iou: 0.090  Mean accuracy: 0.167\nidx:  1  Loss: 0.43105  Mean_iou: 0.413  Mean accuracy: 0.449\nidx:  2  Loss: 0.38317  Mean_iou: 0.280  Mean accuracy: 0.336\nidx:  3  Loss: 0.58265  Mean_iou: 0.222  Mean accuracy: 0.245\nidx:  4  Loss: 1.32589  Mean_iou: 0.106  Mean accuracy: 0.185\nidx:  5  Loss: 0.97682  Mean_iou: 0.190  Mean accuracy: 0.258\nidx:  6  Loss: 0.77247  Mean_iou: 0.307  Mean accuracy: 0.438\nidx:  7  Loss: 0.41628  Mean_iou: 0.301  Mean accuracy: 0.333\nidx:  8  Loss: 0.78444  Mean_iou: 0.333  Mean accuracy: 0.451\nidx:  9  Loss: 1.49985  Mean_iou: 0.132  Mean accuracy: 0.228\nidx:  10  Loss: 1.78627  Mean_iou: 0.052  Mean accuracy: 0.269\nidx:  11  Loss: 1.25724  Mean_iou: 0.147  Mean accuracy: 0.225\nidx:  12  Loss: 0.49928  Mean_iou: 0.313  Mean accuracy: 0.360\nidx:  13  Loss: 0.67959  Mean_iou: 0.228  Mean accuracy: 0.310\nidx:  14  Loss: 1.06066  Mean_iou: 0.118  Mean accuracy: 0.188\nidx:  15  Loss: 0.81382  Mean_iou: 0.358  Mean accuracy: 0.410\nidx:  16  Loss: 0.98205  Mean_iou: 0.228  Mean accuracy: 0.361\nidx:  17  Loss: 1.60988  Mean_iou: 0.131  Mean accuracy: 0.257\nidx:  18  Loss: 0.39914  Mean_iou: 0.353  Mean accuracy: 0.375\nidx:  19  Loss: 0.60060  Mean_iou: 0.331  Mean accuracy: 0.382\nidx:  20  Loss: 1.04416  Mean_iou: 0.175  Mean accuracy: 0.270\nidx:  21  Loss: 1.45739  Mean_iou: 0.209  Mean accuracy: 0.310\nidx:  22  Loss: 0.52071  Mean_iou: 0.304  Mean accuracy: 0.424\nloss mean  0.9200121488260187\nEpoch: 9\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "067e51112c3a45c2ad00a9caf68e4749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/13 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14cf277eba4941e4a84112c99a292e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "idx:  0  Loss: 1.47317  Mean_iou: 0.105  Mean accuracy: 0.232\nidx:  1  Loss: 0.65591  Mean_iou: 0.384  Mean accuracy: 0.489\nidx:  2  Loss: 1.37404  Mean_iou: 0.247  Mean accuracy: 0.351\nidx:  3  Loss: 0.42817  Mean_iou: 0.257  Mean accuracy: 0.288\nidx:  4  Loss: 1.11647  Mean_iou: 0.252  Mean accuracy: 0.362\nidx:  5  Loss: 0.95045  Mean_iou: 0.187  Mean accuracy: 0.251\nidx:  6  Loss: 0.81876  Mean_iou: 0.317  Mean accuracy: 0.384\nidx:  7  Loss: 0.65302  Mean_iou: 0.381  Mean accuracy: 0.445\nidx:  8  Loss: 0.89267  Mean_iou: 0.326  Mean accuracy: 0.436\nidx:  9  Loss: 1.40822  Mean_iou: 0.113  Mean accuracy: 0.165\nidx:  10  Loss: 1.44373  Mean_iou: 0.093  Mean accuracy: 0.296\nidx:  11  Loss: 0.97937  Mean_iou: 0.211  Mean accuracy: 0.266\nidx:  12  Loss: 0.77918  Mean_iou: 0.258  Mean accuracy: 0.313\nidx:  13  Loss: 1.59945  Mean_iou: 0.183  Mean accuracy: 0.282\nidx:  14  Loss: 1.40522  Mean_iou: 0.112  Mean accuracy: 0.191\nidx:  15  Loss: 0.91006  Mean_iou: 0.281  Mean accuracy: 0.354\nidx:  16  Loss: 0.63880  Mean_iou: 0.240  Mean accuracy: 0.296\nidx:  17  Loss: 2.21426  Mean_iou: 0.093  Mean accuracy: 0.217\nidx:  18  Loss: 0.56243  Mean_iou: 0.282  Mean accuracy: 0.360\nidx:  19  Loss: 0.44873  Mean_iou: 0.342  Mean accuracy: 0.365\nidx:  20  Loss: 1.08348  Mean_iou: 0.168  Mean accuracy: 0.244\nidx:  21  Loss: 1.33759  Mean_iou: 0.222  Mean accuracy: 0.312\nidx:  22  Loss: 0.57397  Mean_iou: 0.291  Mean accuracy: 0.407\nloss mean  1.032490092775096\nEpoch: 10\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19535b94f3314fada18a1d6eb0af90f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/13 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "743eded9e56c48d8863e8bef2acd6841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "idx:  0  Loss: 1.06734  Mean_iou: 0.159  Mean accuracy: 0.198\nidx:  1  Loss: 0.45372  Mean_iou: 0.422  Mean accuracy: 0.480\nidx:  2  Loss: 0.57205  Mean_iou: 0.375  Mean accuracy: 0.460\nidx:  3  Loss: 0.51124  Mean_iou: 0.277  Mean accuracy: 0.313\nidx:  4  Loss: 1.15408  Mean_iou: 0.192  Mean accuracy: 0.310\nidx:  5  Loss: 1.07283  Mean_iou: 0.180  Mean accuracy: 0.249\nidx:  6  Loss: 0.71384  Mean_iou: 0.287  Mean accuracy: 0.350\nidx:  7  Loss: 0.64581  Mean_iou: 0.315  Mean accuracy: 0.400\nidx:  8  Loss: 0.85248  Mean_iou: 0.333  Mean accuracy: 0.447\nidx:  9  Loss: 1.16473  Mean_iou: 0.146  Mean accuracy: 0.216\nidx:  10  Loss: 1.74269  Mean_iou: 0.051  Mean accuracy: 0.253\nidx:  11  Loss: 1.16751  Mean_iou: 0.167  Mean accuracy: 0.215\nidx:  12  Loss: 0.65463  Mean_iou: 0.260  Mean accuracy: 0.319\nidx:  13  Loss: 0.96731  Mean_iou: 0.242  Mean accuracy: 0.305\nidx:  14  Loss: 1.25396  Mean_iou: 0.104  Mean accuracy: 0.174\nidx:  15  Loss: 1.03438  Mean_iou: 0.204  Mean accuracy: 0.294\nidx:  16  Loss: 0.72573  Mean_iou: 0.245  Mean accuracy: 0.300\nidx:  17  Loss: 1.44114  Mean_iou: 0.203  Mean accuracy: 0.318\nidx:  18  Loss: 0.47387  Mean_iou: 0.264  Mean accuracy: 0.343\nidx:  19  Loss: 0.37541  Mean_iou: 0.355  Mean accuracy: 0.373\nidx:  20  Loss: 1.09188  Mean_iou: 0.181  Mean accuracy: 0.245\nidx:  21  Loss: 1.35012  Mean_iou: 0.210  Mean accuracy: 0.305\nidx:  22  Loss: 0.55917  Mean_iou: 0.379  Mean accuracy: 0.418\nloss mean  0.9150445979574452\nEpoch: 11\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90be6f4b82f45fdb190de49f5945235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/13 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8aa4f4e2df4986aa074b559f05452d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "idx:  0  Loss: 0.58644  Mean_iou: 0.264  Mean accuracy: 0.290\nidx:  1  Loss: 0.54912  Mean_iou: 0.401  Mean accuracy: 0.471\nidx:  2  Loss: 0.40303  Mean_iou: 0.392  Mean accuracy: 0.436\nidx:  3  Loss: 0.39193  Mean_iou: 0.261  Mean accuracy: 0.289\nidx:  4  Loss: 0.97780  Mean_iou: 0.177  Mean accuracy: 0.278\nidx:  5  Loss: 0.82842  Mean_iou: 0.195  Mean accuracy: 0.254\nidx:  6  Loss: 0.68324  Mean_iou: 0.344  Mean accuracy: 0.431\nidx:  7  Loss: 0.41664  Mean_iou: 0.342  Mean accuracy: 0.375\nidx:  8  Loss: 0.72406  Mean_iou: 0.334  Mean accuracy: 0.449\nidx:  9  Loss: 1.24964  Mean_iou: 0.139  Mean accuracy: 0.214\nidx:  10  Loss: 1.67485  Mean_iou: 0.085  Mean accuracy: 0.256\nidx:  11  Loss: 0.94927  Mean_iou: 0.199  Mean accuracy: 0.232\nidx:  12  Loss: 0.57486  Mean_iou: 0.260  Mean accuracy: 0.320\nidx:  13  Loss: 0.88788  Mean_iou: 0.217  Mean accuracy: 0.288\nidx:  14  Loss: 1.17218  Mean_iou: 0.112  Mean accuracy: 0.189\nidx:  15  Loss: 0.95373  Mean_iou: 0.248  Mean accuracy: 0.328\nidx:  16  Loss: 0.72906  Mean_iou: 0.241  Mean accuracy: 0.308\nidx:  17  Loss: 1.77440  Mean_iou: 0.072  Mean accuracy: 0.207\nidx:  18  Loss: 0.42355  Mean_iou: 0.274  Mean accuracy: 0.355\nidx:  19  Loss: 0.36766  Mean_iou: 0.347  Mean accuracy: 0.376\nidx:  20  Loss: 0.84617  Mean_iou: 0.181  Mean accuracy: 0.224\nidx:  21  Loss: 1.44727  Mean_iou: 0.209  Mean accuracy: 0.304\nidx:  22  Loss: 0.45527  Mean_iou: 0.366  Mean accuracy: 0.408\nloss mean  0.8289815304072007\n"
    }
   ],
   "source": "import torch\nimport numpy as np\nfrom torch import nn\nfrom sklearn.metrics import accuracy_score\nfrom tqdm.notebook import tqdm\n\nos.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n\n# define optimizer\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.00006)\n# move model to GPU\n# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n\nfor epoch in range(12):  # loop over the dataset multiple times\n    print(\"Epoch:\", epoch)\n    loss_list = []\n    model.train()\n\n    \n    for idx, batch in enumerate(tqdm(train_dataloader)):\n        # get the inputs;\n        pixel_values = batch[\"pixel_values\"].to(device)\n        labels = batch[\"labels\"].to(device)\n        \n        #print(pixel_values.shape)\n        #print(labels)\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = model(pixel_values=pixel_values, labels=labels)\n        loss, logits = outputs.loss, outputs.logits\n        print(idx)\n        \n        loss.backward()\n        optimizer.step()\n\n        # evaluate\n#         with torch.no_grad():\n#             upsampled_logits = nn.functional.interpolate(logits, size=labels.shape[-2:], mode=\"bilinear\", align_corners=False)\n#             predicted = upsampled_logits.argmax(dim=1)\n#             metric.add_batch(predictions=predicted.detach().cpu().numpy(), references=labels.detach().cpu().numpy())\n#             metrics = metric.compute(num_labels=len(id2label), ignore_index=255,reduce_labels=False)\n            \n#             if idx % 1 == 0:\n#                 print(\"idx: \", str(idx),\" Loss:\", str(loss.item())[0:7],\" Mean_iou:\", str(metrics[\"mean_iou\"])[0:5], \" Mean accuracy:\", str(metrics[\"mean_accuracy\"])[0:5] )\n#         loss_list.append(loss.item())\n        \n#     loss_value = np.mean(np.array(loss_list))  \n#     print('loss mean ', loss_value)\n    #model.save_pretrained(\"weights/fold_0_\"+str(epoch)+\"_ep_\"+str(loss_value)[0:4]+\".pth\")\n    \n    model.eval()\n    \n    for idx, batch in enumerate(tqdm(valid_dataloader)):\n        # get the inputs;\n        pixel_values = batch[\"pixel_values\"].to(device)\n        labels = batch[\"labels\"].to(device)\n        optimizer.zero_grad()\n        outputs = model(pixel_values=pixel_values, labels=labels)\n        loss, logits = outputs.loss, outputs.logits\n        \n#         loss.backward()\n#         optimizer.step()\n\n        # evaluate\n        with torch.no_grad():\n            upsampled_logits = nn.functional.interpolate(logits, size=labels.shape[-2:], mode=\"bilinear\", align_corners=False)\n            predicted = upsampled_logits.argmax(dim=1)\n            metric.add_batch(predictions=predicted.detach().cpu().numpy(), references=labels.detach().cpu().numpy())\n            metrics = metric.compute(num_labels=len(id2label), ignore_index=255,reduce_labels=False)\n            \n            if idx % 1 == 0:\n                print(\"idx: \", str(idx),\" Loss:\", str(loss.item())[0:7],\" Mean_iou:\", str(metrics[\"mean_iou\"])[0:5], \" Mean accuracy:\", str(metrics[\"mean_accuracy\"])[0:5] )\n        loss_list.append(loss.item())\n        \n    loss_value = np.mean(np.array(loss_list))  \n    print('loss mean ', loss_value)\n    model.save_pretrained(\"weights/fold_4_\"+str(epoch)+\"_ep_\"+str(loss_value)[0:4]+\".pth\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "model.save_pretrained(\"fold_0_1ep.pth\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "model = SegformerForSemanticSegmentation.from_pretrained(\"fold_0_5ep.pth\")\nmodel.to(device)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\nmodel = SegformerForSemanticSegmentation.from_pretrained(\"fold_0_5ep.pth\")\nmodel.to(device)\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\nfor filename in os.listdir(root_dir+'validation/rgb/'):\n    \n    image_path = root_dir+'validation/rgb/'+filename\n    image = Image.open(image_path).convert(\"RGB\")\n\n    inputs = feature_extractor(images=image, return_tensors=\"pt\").to(device)\n    resized_img = image.resize((128, 128))\n    image_np = np.array(resized_img)\n    \n    model.eval()\n    with torch.no_grad():\n        outputs = model(inputs.pixel_values).logits\n        upsampled_logits = nn.functional.interpolate(outputs,size=image.size[::-1],mode='bilinear',align_corners=False)\n        print(upsampled_logits.shape)\n        seg = upsampled_logits.cpu().argmax(dim=1)[0].numpy()\n        replacement_dict = {0: 10, 1: 11, 2:12, 3:13, 4:16, 5:17, 6:0}\n        seg2 = np.vectorize(replacement_dict.get)(seg)\n        seg3 = np.stack([seg2] * 3, axis=-1)\n        \n        np.save('/home/klimenko/seg_materials/VAL_SEGFORMER/results/'+filename.replace(\".png\", \".npy\"), seg2)\n        \n        \n        #image = Image.fromarray(seg3.astype(np.uint8))\n        #image.save('/home/klimenko/seg_materials/VAL_SEGFORMER/results/'+filename.replace(\".png\", \".jpg\"))\n    \n    \n\n\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "image_path = \"/home/klimenko/seg_materials/VAL_SEGFORMER/data/0/train/rgb/Copy of YAqsjUKCMc_DkjpPMtrIcQ_180.png\"  # replace with your image path\nimage = Image.open(image_path).convert(\"RGB\")\n\ninputs = feature_extractor(images=image, return_tensors=\"pt\").to(device)\nresized_img = image.resize((128, 128))\nimage_np = np.array(resized_img)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "image.size"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\nupsampled_logits = nn.functional.interpolate(outputs,size=(1000, 1000)[::-1],mode='bilinear',align_corners=False)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "upsampled_logits.shape"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "model.eval()\nwith torch.no_grad():\n    outputs = model(inputs.pixel_values).logits\n    upsampled_logits = nn.functional.interpolate(outputs,size=(1000, 1000)[::-1],mode='bilinear',align_corners=False)\n    print(upsampled_logits.shape)\n    seg = upsampled_logits.cpu().argmax(dim=1)[0].numpy()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "seg.shape"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\noutputs_np = upsampled_logits.cpu().numpy()[0]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "{\n  \"0\": \"nothing\",\n  \"1\": \"10_glazing\",\n  \"2\": \"11_concrete\",\n  \"3\": \"12_masonry\",\n  \"4\": \"13_siding\",\n  \"5\": \"16_stucco\",\n  \"6\": \"17_metal\"\n}\n\n\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "replacement_dict = {0: 10, 1: 11, 2:12, 3:13, 4:16, 5:17, 6:0}\nseg2 = np.vectorize(replacement_dict.get)(seg)\nseg3 = np.stack([seg2] * 3, axis=-1)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "seg2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import cv2\nimage_path = \"/home/klimenko/seg_materials/VAL_SEGFORMER/data/0/train/labels/Copy of YAqsjUKCMc_DkjpPMtrIcQ_180.png\"\nqq = cv2.imread(image_path)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%matplotlib notebook\nplt.imshow(qq*10)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "seg = outputs.logits.cpu().argmax(dim=1)[0].numpy()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(np.unique(seg))"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facade",
   "language": "python",
   "name": "facade"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
